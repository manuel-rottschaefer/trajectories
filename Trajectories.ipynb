{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manumeehl/trajectories/blob/main/Trajectories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "''' SYSTEM AND PYTHON PACKAGES '''\n",
        "!apt install tesseract-ocr\n",
        "!pip install opencv-python-headless pytesseract pytube\n",
        "\n",
        "from google.colab.patches import cv2_imshow as show\n",
        "from pytesseract import image_to_string as img_to_str\n",
        "from scipy.interpolate import interp1d\n",
        "from pytube import YouTube, Playlist\n",
        "from scipy.signal import find_peaks\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import math\n",
        "import cv2\n",
        "import re\n",
        "import os"
      ],
      "metadata": {
        "id": "H80IWIdCRriX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' GENERIC PYTHON UTILITIES '''\n",
        "def contains_substring(string, list):\n",
        "  ''' Check if a string contains a substring from a list of strings '''\n",
        "  for substring in list:\n",
        "    if substring in string:\n",
        "      return True\n",
        "  return False"
      ],
      "metadata": {
        "id": "5A7Wwbg4lRBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' VIDEO UTILITIES '''\n",
        "def get_video(url):\n",
        "  ''' Download a Video from YouTube and save it as MP4 '''\n",
        "  vid = YouTube(url)\n",
        "  print(f\"Downloading Video '{vid.streams[0].title}'\")\n",
        "  vid.streams.filter(progressive=True, file_extension='mp4')\\\n",
        "  .order_by('resolution').desc().first()\\\n",
        "  .download(output_path='temp', filename='launch.mp4')\n",
        "  print('Download complete')\n",
        "  vidfile = cv2.VideoCapture('temp/launch.mp4')\n",
        "  props = {'title': vid.title, 'date': vid.publish_date, 'length': vid.length}\n",
        "  return vidfile, props\n",
        "\n",
        "def show_frame(vid, position):\n",
        "  ''' Show a single frame from a video file '''\n",
        "  # ToDo: Read the video here\n",
        "  vid.set(cv2.CAP_PROP_POS_FRAMES, int(position))\n",
        "  ret, frame = vid.read()\n",
        "  show(frame)"
      ],
      "metadata": {
        "id": "nwUp0dTGSX1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' TIME CONVERSION TOOLS '''\n",
        "def clock_to_secs(clockstring):\n",
        "  ''' Convert a mission clock string to an integer second value '''\n",
        "  tense = -1 if clockstring[:2] == 't-' else 1\n",
        "  # Remove the T+- sign\n",
        "  clockstring = clockstring [2:]\n",
        "  # Get the seconds\n",
        "  units = clockstring.split(':')\n",
        "  hours = int(units[0])\n",
        "  minutes = int(units[1])\n",
        "  seconds = int(units[2])\n",
        "\n",
        "  return tense * (hours * 3600 + minutes * 60 + seconds)\n",
        "\n",
        "def elapsed_secs(frame1, frame2, fps):\n",
        "  ''' Get the time between two frames in a video '''\n",
        "  return round((frame2 - frame1) / fps, 2)"
      ],
      "metadata": {
        "id": "1maxk5cRdZUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' OCR PARSING AND DATA EXTRACTION '''\n",
        "def parse_clock(string):\n",
        "  ''' Extract mission clock, altitude and velocity from a given string '''\n",
        "  mission_clock = re.findall(r't[+-]\\d{2}:\\d{2}:\\d{2}', string.lower().replace(' ', ''))\n",
        "  if mission_clock: return mission_clock[0]\n",
        "  else: return None\n",
        "\n",
        "def parse_trajectory(string):\n",
        "  ''' Extract altitude and velocity from a given string '''\n",
        "  trajectory = None\n",
        "  # Apply a blacklist\n",
        "  for w in ['stage 1', 'stage 2', 'falcon 9', 'starlink']:\n",
        "    string = string.replace(w, '')\n",
        "  # Find all numbers in the string\n",
        "  num_scan = re.findall(r'\\d+(?:\\.\\d+)?', string.lower())\n",
        "  vel, alt = interpret_trajectory_numbers(num_scan)\n",
        "  return {'vel': vel, 'alt': alt}\n",
        "\n",
        "def interpret_trajectory_numbers(numbers):\n",
        "  ''' From a list of numbers, determine which is the velocity and which the altitude based on a few requirements '''\n",
        "  # Convert all numbers to float and remove duplicates\n",
        "  numbers = list(set([float(x) for x in numbers]))\n",
        "  # Check if two numbers are available, else return default value\n",
        "  if len(numbers) == 2:\n",
        "    # When speed is zero, altitude is the larger number (shortly after liftoff)\n",
        "    if 0.0 in numbers:\n",
        "      return [0, max(numbers)]\n",
        "    else:\n",
        "      return [max(numbers), min(numbers)]\n",
        "  else:\n",
        "    return [0, 0]\n",
        "\n",
        "def extract_data(vid, scope=[]):\n",
        "  ''' Collect all datapoints from a frame '''\n",
        "  ret, frame = vid.read()\n",
        "  # Get the regions of interest\n",
        "  clockframe, frame_s1, frame_s2 = get_snippets(frame)\n",
        "  ocr_config = '--psm 11'\n",
        "  # Scan for data\n",
        "  clock = parse_clock(img_to_str(clockframe, config={}))\n",
        "  # Trajectory is empty by default\n",
        "  trj_s1, trj_s2 = {}, {}\n",
        "\n",
        "  if 's1' in scope:\n",
        "    trj_s1 = parse_trajectory(img_to_str(frame_s1, config=ocr_config))\n",
        "  if 's2' in scope:\n",
        "    trj_s2 = parse_trajectory(img_to_str(frame_s2, config=ocr_config))\n",
        "\n",
        "  return clock, trj_s1, trj_s2"
      ],
      "metadata": {
        "id": "ge8m4Hp9RurH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' VIDEO PROCESSING '''\n",
        "def preprocess(frame):\n",
        "  ''' Apply preprocessing filters to a frame '''\n",
        "  return cv2.bitwise_not(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
        "\n",
        "def get_snippets(frame):\n",
        "  ''' Cut out regions of interest and apply filters for OCR '''\n",
        "  height, width, _ = frame.shape\n",
        "\n",
        "  stage1 = preprocess(frame[height-80:height-40,50:300])\n",
        "  stage2 = preprocess(frame[height-80:height-40,width-300:width-50])\n",
        "  clock = preprocess(frame[height-110:height-20,int(width/2-100):int(width/2+100)])\n",
        "\n",
        "  return clock, stage1, stage2"
      ],
      "metadata": {
        "id": "qntY3Y59Cq60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' VIDEO PARAMETER SCAN '''\n",
        "def await_liftoff(vid):\n",
        "  ''' Identify the frame at which liftoff occurs '''\n",
        "  # Look for the clock every minute\n",
        "  framepos, interval = 0, int(30 * vid.get(cv2.CAP_PROP_FPS))\n",
        "  first_clock = None\n",
        "  # Await first mission clock appearance\n",
        "  while vid.isOpened():\n",
        "    vid.set(cv2.CAP_PROP_POS_FRAMES, int(framepos))\n",
        "    framepos += interval\n",
        "    clock, t1, t2 = extract_data(vid)\n",
        "\n",
        "    # Wait until the mission clock first appears\n",
        "    if clock and not first_clock:\n",
        "      first_clock = clock\n",
        "      interval = 1\n",
        "\n",
        "    # Now wait for the next full second\n",
        "    if first_clock and clock != first_clock:\n",
        "      framepos -= clock_to_secs(clock) * vid.get(cv2.CAP_PROP_FPS)\n",
        "      return framepos"
      ],
      "metadata": {
        "id": "gMv3SS_RZbvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' TRAJECTORY ANALYSIS '''\n",
        "\n",
        "def detect_meco(values: list, window:int=5) -> bool:\n",
        "  return False\n",
        "  #print(values)\n",
        "  #if len(values) < window: return False\n",
        "  #last_vals = values[-window:]\n",
        "  #return last_vals == sorted(set(last_vals), reverse=True)\n",
        "\n",
        "def detect_landing(trajectory): -> bool:\n",
        "  if trajectory['vel'] < 1 and trajectory['alt'] < 1:\n",
        "    print('Landing confirmed!')\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "IgeIfpPUaqAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' CONTINUOUS DATA SCAN '''\n",
        "waypoints = {\n",
        "    'MECO' : False,\n",
        "    'landing': False\n",
        "}\n",
        "\n",
        "def process_launch(vid, liftoff_frame, duration):\n",
        "  framepos = liftoff_frame\n",
        "  trajectory = pd.DataFrame(columns = ['clock', 'secs', 's1_alt', 's1_vel', 's2_alt', 's2_vel'])\n",
        "\n",
        "  while vid.isOpened():\n",
        "    vid.set(cv2.CAP_PROP_POS_FRAMES, int(framepos))\n",
        "    fps = vid.get(cv2.CAP_PROP_FPS)\n",
        "    ret, frame = vid.read()\n",
        "\n",
        "    # If MECO has not happened already, check for it and only look for Stage 1 telemetry\n",
        "    scope = ['s1', 's2']\n",
        "    if not waypoints['MECO']:\n",
        "        waypoints['MECO'] = detect_meco(trajectory['s1_vel'].values.tolist(), window=5)\n",
        "        # Monitor Stage 1 telemetry only\n",
        "        scope = ['s1']\n",
        "    clock, trj_s1, trj_s2 = extract_data(vid, scope)\n",
        "\n",
        "    # Check if any trajectory can be stored\n",
        "    if clock and (trj_s1 or trj_s2):\n",
        "      # Modify trajectory for each mission phase, then save it\n",
        "      # Before MECO if first stage trajectory is available\n",
        "      if not waypoints['MECO'] and trj_s1 and not trj_s2:\n",
        "        trj_s2 = trj_s1\n",
        "\n",
        "      # After MECO if both telemetries are available\n",
        "      if waypoints['MECO'] and trj_s1 and trj_s2:\n",
        "        # Check if rocket has landed\n",
        "        if not waypoints['landing']:\n",
        "          waypoints['landing'] = check_landing(trj_s1)\n",
        "\n",
        "      # After MECO if only second Stage trajectory is available\n",
        "      if waypoints['MECO'] and not trj_s1 and trj_s2:\n",
        "        trj_s1 = {'vel': 0, 'alt':0}\n",
        "\n",
        "      # Save the data\n",
        "      trj = list(trj_s1.values()) +list(trj_s2.values())\n",
        "      trajectory.loc[len(trajectory)] = [clock, clock_to_secs(clock)] + trj\n",
        "\n",
        "    else:\n",
        "      # Skip a few frames forward for better chances of successfull OCR\n",
        "      framepos += 5\n",
        "\n",
        "    # Stop at first stage landing or at limit\n",
        "    if waypoints['landing'] or framepos > liftoff_frame + (duration*fps):\n",
        "      break\n",
        "\n",
        "    # Skip to next second\n",
        "    framepos += int(fps - ((framepos - liftoff_frame) % fps)) + 3\n",
        "\n",
        "  return trajectory"
      ],
      "metadata": {
        "id": "qmFZnT-LCDWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_charts(title, path, trj):\n",
        "  # Process data\n",
        "  for i in ['s1_alt', 's1_vel', 's2_alt', 's2_vel']:\n",
        "    trj[i] = remove_spikes(trj[i].values.tolist())\n",
        "    trj[i] = interpolate_curve(trj['secs'].values.tolist(), trj[i])[1]\n",
        "\n",
        "  # Define the x axis\n",
        "  clock = trj['secs'].values.tolist()\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.xaxis.set_major_formatter(ticker.FuncFormatter(format_x_axis))\n",
        "  plt.title(f'{title} Velocity')\n",
        "  plt.xticks(rotation=45)\n",
        "  ax.yaxis.set_major_formatter(ticker.FuncFormatter(vel_y_axis))\n",
        "  ax.plot(clock, trj['s1_vel'], label='Stage 1')\n",
        "  ax.plot(clock, trj['s2_vel'], label='Stage 2')\n",
        "  plt.legend()\n",
        "  plt.savefig(f'{path}/velocity.png')\n",
        "  plt.close()\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.xaxis.set_major_formatter(ticker.FuncFormatter(format_x_axis))\n",
        "  plt.title(f'{title} Altitude')\n",
        "  plt.xticks(rotation=45)\n",
        "  ax.yaxis.set_major_formatter(ticker.FuncFormatter(alt_y_axis))\n",
        "  plt.plot(clock, trj['s1_alt'], label='Stage 1')\n",
        "  plt.plot(clock, trj['s2_alt'], label='Stage 2')\n",
        "  plt.legend()\n",
        "  plt.savefig(f'{path}/altitude.png')\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "LUaFTnmhvQgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' DATA POST-PROCESSING '''\n",
        "def remove_spikes(data):\n",
        "    pos_peaks, _ = find_peaks(data)\n",
        "    neg_peaks, _ = find_peaks(-np.array(data))\n",
        "    for peak_index in [*pos_peaks, *neg_peaks]:\n",
        "        data[peak_index] = data[peak_index - 1]\n",
        "    return data\n",
        "\n",
        "def interpolate_curve(x, y):\n",
        "    x_floor = np.floor(x)\n",
        "    x_smooth = np.linspace(x_floor[0], x_floor[-1], len(x_floor))\n",
        "\n",
        "    f = interp1d(x_floor, y, kind='quadratic')\n",
        "    y_smooth = f(x_smooth)\n",
        "\n",
        "    return x_smooth, y_smooth\n",
        "\n",
        "#Axis formatters\n",
        "def format_x_axis(seconds, _):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "    return f\"T+{hours:02}:{minutes:02}:{seconds:02}\"\n",
        "\n",
        "def vel_y_axis(value, _):\n",
        "    return f\"{int(value)} km/h\"\n",
        "\n",
        "def alt_y_axis(value, _):\n",
        "    return f\"{value} km\""
      ],
      "metadata": {
        "id": "rwROF-JV_JEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' MAIN ROUTINE '''\n",
        "# Get YouTube Videos\n",
        "def get_videos_of_playlist(playlist_url):\n",
        "  return Playlist(playlist_url).video_urls\n",
        "\n",
        "playlist_url = 'https://www.youtube.com/playlist?list=PLBQ5P5txVQr8qmgRWbVyqhhRzb3Xprefy'\n",
        "playlist = get_videos_of_playlist(playlist_url)\n",
        "vidpath = 'temp/launch.mp4'\n",
        "\n",
        "# Filter out videos which are not launches\n",
        "blacklist = ['docking', 'undocking']\n",
        "\n",
        "os.system('mkdir launches')\n",
        "\n",
        "for url in playlist[:2]:\n",
        "  # Analyze the current video\n",
        "  title = YouTube(url).title\n",
        "\n",
        "  # Skip non-launch videos\n",
        "  if contains_substring(title.lower(), blacklist):\n",
        "    continue\n",
        "\n",
        "  vid, props = get_video(url)\n",
        "  print(f\"Processing video {props['title']} from {props['date']}\")\n",
        "\n",
        "  print('Searching liftoff frame...')\n",
        "  liftoff_frame = await_liftoff(vid)\n",
        "\n",
        "  # Skip forward\n",
        "  start_frame = liftoff_frame + 6 * 60 * fps\n",
        "\n",
        "  print('Liftoff registered, now monitoring trajectories...')\n",
        "  trajectory = process_launch(vid, liftoff_frame, 10 * 60)\n",
        "\n",
        "  # Create a new folder for this launch\n",
        "  path = f\"launches/{props['title'].replace(' ', '_')}\"\n",
        "  os.system(f'mkdir {path}')\n",
        "\n",
        "  with open(f'{path}/trajectory.csv', 'w') as json_file:\n",
        "    json.dump(trajectory.to_csv(), json_file)\n",
        "\n",
        "  create_charts(props['title'], path, trajectory)"
      ],
      "metadata": {
        "id": "ytb_Z3FqULem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "70d7214f-6097-470f-8e0e-62d17cab5f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Video 'Space Development Agency’s Second Tranche 0 Mission'\n",
            "Download complete\n",
            "Processing video Space Development Agency’s Second Tranche 0 Mission from 2023-09-02 00:00:00\n",
            "Searching liftoff frame...\n",
            "Liftoff registered, now monitoring trajectories...\n",
            "[0, 0.1]\n",
            "[0, 27.0]\n",
            "[0, 13.0]\n",
            "[0, 10.0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-6577a29f6c30>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Liftoff registered, now monitoring trajectories...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0mtrajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliftoff_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;31m# Create a new folder for this launch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-6d44fc8022dd>\u001b[0m in \u001b[0;36mprocess_launch\u001b[0;34m(vid, liftoff_frame, duration)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Monitor Stage 1 telemetry only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m's1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mclock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrj_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrj_s2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Check if any trajectory can be stored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-5c66a354c8f5>\u001b[0m in \u001b[0;36mextract_data\u001b[0;34m(vid, scope)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m# Get the regions of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mclockframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_s2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_snippets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0mocr_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'--psm 11'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m# Scan for data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-85b0567b48bf>\u001b[0m in \u001b[0;36mget_snippets\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_snippets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;34m''' Cut out regions of interest and apply filters for OCR '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mstage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}